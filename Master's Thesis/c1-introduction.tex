\chapter{Overview}

The contents of this thesis fall within the research area known as Direct Volume Rendering, or DVR. In the vast majority of cases, an object is rendered using a polygonal mesh to represent its surface geography, and textured using a static image. The lighting applied to this mesh can be described using a Bidirectional Reflectance Distribution function, or BRDF, a surface rendering algorithm that only solves for light from the surface points of an object. As such, when information from the internal structure of an object is required, this method is not suitable.

Direct Volume Rendering techniques allow for the internal structure of an object to be taken into account when rendering the surface image. In these cases, the information cannot be stored simply within a 2D image, but instead within a volumetric grid. This grid consists of image slices sampled from the original object at regular intervals, with each slice containing a regular pattern of elements. The elements of information contained within this grid are known as voxels, the 3D counterpart to pixels. At lower resolutions of data, volumetrically rendered objects appear to be made up of tiny cubes, each of which is a voxel.

Voxels are assigned what is known as an intensity or a material value. This range for this value can vary depending on the data set, but generally it is set between 0 and 255. Using what is known as a Transfer Function, these material values are mapped to an RGBA colour. In many cases, this transfer function doesn't assign each individual material a colour, but instead assigns a colours to ranges of materials. 

This project deals with the question of visibility within this 3D dataset. With the data stored and rendered in this way, it is possible for important features to be hidden behind less important ones. While the alpha values of particular materials can be changed within the transfer function to better see or ignore it, this is a time consuming process, and automation is preferable. Many algorithms have been developed to deal with this problem with varying degrees of success. 

This thesis aims to calculate information for a volumetric gridset on a per-voxel basis in real time, for the purpose of being used by other researchers to better automate and optimise their visibility algorithms. The two information types dealt with are voxel visibility and saliency. 

The Visibilitity of a voxel is a measure of how influencial that voxel is to the final image. The visibility of materials within a volumetric grid is well established, through the creation of visibility histograms etc, but in many cases, researchers wish to know the visibility of individual voxels within the final rendered image. For this reason, visibility fields were introduced, which contain the visibility of each individual voxel within the grid. Saliency is a measure of how noticible a voxel is based on the colour assigned to it by the transfer function. To compute this, the idea of a saliency field was introduced. Unlike a visibility field, a saliency field is view independent, and so does not need to be recalculated each time the camera moves relative to the object.

Calculating these fields can be quite expensive, and while it is possible to do these calculations through the rendering pipeline, it is not made for this purpose. However, OpenGL introduced a new type of shader known as a Compute Shader. Compute Shaders are general purpose shaders, built for large calculations. This makes them perfect for the calculations required by this project. Unlike other solutions available such as CUDA and OpenCL, Compute Shaders are native to OpenGL and so do not require any external files to run. They also are coded through GLSL, making them ideal for new users with experience in shader design.

\section{Structure}

The structure of this thesis is as follows: Chapters 2 and 3 provide an overview of related work within the fields that this thesis is a part of. Chapter 2 talks about Volumetric Rendering, briefly talking about the history before moving into the main techniques used. Chapter 3 provides an explanation of Compute Shaders. Chapter 4 details the implementation of the project, and how each of the core components operate. Chapter 5 walks through the evaluation of the project, presenting the results that were obtained during testing. Chapter 6 is a summary of the work. 
